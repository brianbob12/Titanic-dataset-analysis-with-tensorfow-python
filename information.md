This is an attempt at using the tenzorflow python library in order to produce a program capable in predicting patterns in the dataset through the form of predicting survival of passengers. The program used a set of dense layers of neurons in a neural net. The program has flexibility in the structure of the layers as well as the activation function. 

Many sets of activation functions were tested however when leeky_relu or linear activation was used, the program suffered from diminishing gradients.  The network used nineteen input neurons for the one-hot formatted data. Code for one-hot formatting was unnecessary as it is incorporated in the tenzorflow library.  The dataset was iterated over 180 times. Networks with fewer layers and larger layers tended to learn more quickly whilst deeper networks took more iterations to reach the same accuracy. 

However the structure, the accuracy never exceeded significant predictions as the network tended to predict lower values of survival with the little deviation between data points. This is likely due to underfitting to the training data set as shown through scores in the hold-out data set being similar to training accuracy.  Furthermore, dropout regulation could be used in training in order to spread the weights and biases over the network limiting overfitting. The dropout regulation would prevent the network from relying on specific neurons and enable the Adam Optimizer to find new lew local mediums for the dataset.  

The project did not work as the network was unable to discern any significant patterns and the project did not achieve utility. Normalization of the data could be used in order to aid the network; centering the data and normalizing the inputs would have made the program more applicable to small datasets. The training dataset was only 891 data points with 30 of those used for the hold-out datapoints. The program would have been more successful given a larger data set. 
